# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ud5Gg5qH7rCKbjzOhyMvfxBo1UNwEv9V
"""

# Commented out IPython magic to ensure Python compatibility.
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import tensorflow as tf
# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
np.random.seed(2)

data=pd.read_csv("/content/drive/My Drive/Internship/prima-indians-diabetes.csv")
data.head()

data.tail()

data = data.rename(index=str, columns={"6":"preg"})
data = data.rename(index=str, columns={"148":"gluco"})
data = data.rename(index=str, columns={"72":"bp"})
data = data.rename(index=str, columns={"35":"stinmm"})
data = data.rename(index=str, columns={"0":"insulin"})
data = data.rename(index=str, columns={"33.6":"mass"})
data =data.rename(index=str, columns={"0.627":"dpf"})
data = data.rename(index=str, columns={"50":"age"})

data = data.rename(index=str, columns={"1":"target"})
data.head()

data.describe()





mpl.rcParams['figure.figsize']=25,15
plt.matshow(data.corr())
plt.yticks(np.arange(data.shape[1]),data.columns)
plt.yticks(np.arange(data.shape[1]),data.columns)
plt.colorbar()

data.hist()



mpl.rcParams['figure.figsize']=10,8
plt.bar(data['target'].unique(), data['target'].value_counts(), color = ['blue', 'pink'])
plt.xticks([0,1])
plt.xlabel('Target class')
plt.ylabel('count')
plt.title('count of our each target class')

# split into input (X) and output (Y) variables, splitting csv data
#X = dataset[:,:,-1]
#Y = dataset[:,8]
X = data.iloc[:, :-1]
Y = data.iloc[:,8]

X

#split dataset into train test and validation set

X_train_full, X_test, y_train_full, y_test = train_test_split(X, Y, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)

X_train

#convert data into sandard scaler formate
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)

X_train

import numpy as np
import tensorflow as tf
np.random.seed(42)
tf.random.set_seed(42)

X_train.shape

model = Sequential()
model.add(Dense(20, input_dim=8, activation='relu')) # input layer requires input_dim param
model.add(Dense(15, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dropout(.25))
model.add(Dense(1, activation='sigmoid')) # sigmoid instead of relu for final probability between 0 and 1



model.summary()

model.compile(loss="binary_crossentropy", optimizer="SGD", metrics=['accuracy'])

model_history = model.fit(X_train, y_train, epochs=200, validation_data=(X_valid, y_valid))

model_evaluate = model.evaluate(X_test, y_test)
model_evaluate

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
pd.DataFrame(model_history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca()

plt.show()

X_new=X_test[:3]
X_new

y_pred = model.predict(X_new)
print (y_pred)

y_test[:3]